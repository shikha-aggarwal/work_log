### 01 March 2021
  - Week 2 of linear algebra coursera + assignments
  - CS224N: Lecture 2 – Word Vectors and Word Senses

### 02 March 2021
  - Week 3 of linear algebra coursera - gaining radical perspective on meaning of matrices! + assignments (3 hours)
  - Attended Outlander Labs demo day: interesting find - Chip11 (open-source chip designs)
  - CS224N coding assignment 2: Derived word2vec cost, derivatives. Implemented naive softmax cost, SGD. (4 hours)

### 03 March 2021
- Week 4 of linear algebra coursera - Gram Schmidt process, orthogonal matrices, Einstein’s summation method
- assignments.

### 04 March 2021
- CS224N assignment 2 quiz.
- CS224N assignment extra credit.

### 05 March 2021
- Week 5 of linear algebra course: Eigenvalues, vectors - their importance in applying transformations on diagonal matrix.

### 06, 07 March 2021 - weekend

### 08 March 2021
- Week 1 of Multivariate Algebra course
- CS224N - Lecture 3

### 09 March 2021
- CS224N - Lecture 4
Week 2 of Multivariate Algebra course - Jacobian, Hessian

### 10 March 2021
- CS224N - Lecture 5 - Phrase structure vs Dependency Parsing. Dependency parsing history, development, evaluation.

### 11 March 2021
- CS224N - Quiz.
- CS224N - code not complete.

### 12 March 2021
- Code not working
- weekend at Mohonk Mountain.

### 14 March 2021
- Code complete dependency parsing!

### 15 March 2021
- CS224N - Lecture 6
    - Language modeling,
    - RNNs,
    - Evaluation of LM (perplexity)
- CS224N - Lecture 7
    - Vanishing/exploding Gradient in RNNs.
    - LSTM, GRU - mitigate.
    - Very good lecture about minute details in handling gradients.
    - Optimizations: Residual, Dense, and Highway connections.
    - Bidirectional and Multi-layer RNNs.
- CS224N - Lecture 8
    - Machine translation problem,
    - SMT,
    - NMT -- started with seq-to-seq.
    - seq-to-seq consists of Encoder RNN and decoder RNN.
    - BLEU score.
    - Excellent intuition of Attention! Idea: on each step of the decoder, use direct connection to the encoder to focus on a particular part of the source sequence.
    - Generalization of attention.
    - Variants of attention scores: dot-product, multiplicative attention, additive.

### 16 March 2021
- Implemented a NMT model: using bidirectional LSTM for encoding and another unidirectional LSTM for decoding. Spent a lot of time taking care of dimensions of tensors but got stuck with one error which turned out to be application of softmax on a wrong dimension. :D Glad it was sorted out before sleeping though!

### 17 March 2021
- Ran the NMT code on Google Colab - figured out how to use GPUs there.
